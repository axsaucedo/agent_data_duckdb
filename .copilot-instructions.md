# agent_data DuckDB Extension - Development Instructions

## Critical Caveats

### 1. JSONL File Handling - DANGER ZONE
**⚠️ NEVER print, cat, or view full JSONL files from copilot_raw/ or test/data/**

The JSONL conversation files can be **massive** (hundreds of MB). Incorrect commands will:
- Pollute the entire context window
- Cause memory issues
- Result in incomplete/corrupted output

**Safe Commands:**
```bash
# View first N bytes only
head -c 500 file.jsonl

# Count lines without reading content
wc -l file.jsonl

# Get first N complete JSON lines
head -n 3 file.jsonl | jq -c '.'

# Sample specific fields only
head -n 10 file.jsonl | jq -c '{type, timestamp}'

# Get file size
ls -lh file.jsonl
```

**NEVER DO:**
```bash
cat file.jsonl           # DANGEROUS
less file.jsonl          # DANGEROUS (without limits)
jq '.' file.jsonl        # DANGEROUS (reads entire file)
```

### 2. Build and Test
```bash
make configure   # First time setup
make debug       # Build debug extension
make test        # Build + run all tests
```

### 3. Testing Strategy
- Always run tests with limited data first
- Use `test/data/` synthetic data, not `copilot_raw/`
- Run `make test` after every change
- Tests are assertion-driven (PASS/FAIL output)

## Project Structure

```
agentic-copilot/
├── .copilot-instructions.md  # THIS FILE
├── Cargo.toml                # Rust crate (agent_data)
├── Makefile                  # Build system
├── src/                      # Rust extension source
│   ├── lib.rs               # Entry point (registers 5 functions)
│   ├── vtab.rs              # Generic VTab framework (TableFunc trait)
│   ├── types.rs             # Serde types for JSON/JSONL
│   ├── utils.rs             # Path resolution, file discovery
│   ├── conversations.rs     # read_conversations()
│   ├── plans.rs             # read_plans()
│   ├── todos.rs             # read_todos()
│   ├── history.rs           # read_history()
│   └── stats.rs             # read_stats()
├── test/
│   ├── data/                # Synthetic ~/.claude mock
│   └── sql/                 # SQL test files
├── scripts/
│   ├── test.sh              # SQL test runner
│   └── smoke_test.sh        # Python/DuckDB smoke test
├── examples/
│   └── explore.py           # Marimo notebook
├── docs/                    # Documentation
└── copilot_raw/             # Real data - READ ONLY, HANDLE WITH CARE
```

## Architecture

The extension uses a **generic VTab framework** in `vtab.rs`:
- `TableFunc` trait: each module implements `columns()`, `load_rows()`, `write_row()`
- `GenericVTab<T>`: handles all DuckDB VTab lifecycle (bind/init/func/named_parameters)
- Shared vector helpers: `set_varchar`, `set_i64`, `set_bool` in vtab.rs

To add a new table function:
1. Create `src/new_module.rs` implementing `TableFunc`
2. Register in `lib.rs` with `GenericVTab::<NewModule>::register()`

## Extension API

All functions accept optional `path` parameter (defaults to ~/.claude):

```sql
LOAD 'build/debug/agent_data.duckdb_extension';

-- Default to ~/.claude
SELECT * FROM read_conversations();

-- Explicit path
SELECT * FROM read_conversations(path='test/data');
SELECT * FROM read_plans(path='test/data');
SELECT * FROM read_todos(path='test/data');
SELECT * FROM read_history(path='test/data');
SELECT * FROM read_stats(path='test/data');
```

## Key Join Keys

- `session_id`: links conversations ↔ history ↔ todos
- `project_path` / `project`: links conversations ↔ history
- `slug` / `plan_name`: links conversations ↔ plans

## Verification Checklist

Before committing:
- [ ] `make test` passes (54+ SQL tests + Python smoke test)
- [ ] No large files accidentally committed
- [ ] Build artifacts excluded from git
- [ ] Documentation updated if API changes
